{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2ewqHXelrCdS"
      },
      "outputs": [],
      "source": [
        "!pip install IPython \n",
        "!pip install openai \n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai \n"
      ],
      "metadata": {
        "id": "N3Hf6ZaJrUXZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "future scope application : chain-of-thought process for code generation, deepfake frontend "
      ],
      "metadata": {
        "id": "W4RdWGBgrwmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gpt3(text):\n",
        "    openai.api_key='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'\n",
        "    response = openai.Completion.create(\n",
        "    model=\"text-davinci-003\",\n",
        "    prompt=text,\n",
        "    temperature=0.7,\n",
        "    max_tokens=2000,\n",
        "    top_p=1.0,\n",
        "    frequency_penalty=0.0,\n",
        "    presence_penalty=1\n",
        "    )\n",
        "    content=response.choices[0].text\n",
        "    print(content)\n",
        "    return response.choices[0].text"
      ],
      "metadata": {
        "id": "G5xMTzhZrYT5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_understanding_part=input(\"select part you cant understand: \")\n",
        "explain_work='explain '+non_understanding_part+'to a 5 year old'\n",
        "responce=gpt3(explain_work)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncpHQ4KjrolE",
        "outputId": "e8a425aa-848c-43ed-9afd-07ff90dcf7b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "select part you cant understand:  tms  summary models for research papers student-advisor pairing  Project recommendations    Error detection and Correction and Plagiarism detection This will help the student to decrease the amount of draft reviews and prevent thesis topic plagiarism\n",
            "\n",
            "\n",
            "TMS summary models are used in research papers to help match students with advisors, make project recommendations, detect and correct errors, and detect plagiarism. This can help students save time by reducing the number of drafts they have to review, and make sure their thesis topics are original.\n"
          ]
        }
      ]
    }
  ]
}